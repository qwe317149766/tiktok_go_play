# Linux 环境示例（复制为 .env.linux 或 env.linux 后填写真实配置）

# 配置文件版本号：用于和 requirements.txt 同步（当前 curl_cffi 版本）
CURL_CFFI_VERSION=0.14.0

# 生成器开关
SAVE_TO_REDIS=1
SAVE_TO_FILE=1

# mwzzzh_spider 任务数：
# 默认直接复用 MAX_GENERATE（只改一个配置即可同时控制生成数量/任务数量）。
# 如需单独覆盖，再手动加一行：MWZZZH_TASKS=100

# 最多生成设备数量（上限 100000）
MAX_GENERATE=100000

# mwzzzh_spider.py（轮询补齐模式：Linux 默认开启；Windows 可通过 MWZZZH_POLL_MODE=1 调试）
# - 轮询补齐：检查 Redis 设备池数量，缺多少就自动注册补齐多少
# MWZZZH_POLL_MODE=1
# MWZZZH_POLL_INTERVAL_SEC=10
# 设备池最终数量：统一使用 REDIS_MAX_DEVICES（不要再配置 REDIS_TARGET_DEVICES，已废弃）
# 单轮补齐最大注册数量（避免一次补太多）
# MWZZZH_POLL_BATCH_MAX=2000

# mwzzzh_spider.py keep-alive（Session 复用 + 达到最大次数自动淘汰重建）
# - 默认开启（MWZZZH_KEEPALIVE=1）
# - 每个 Session 处理到 MWZZZH_SESSION_MAX_REQUESTS 次“任务”就会自动淘汰重建
MWZZZH_KEEPALIVE=1
MWZZZH_SESSION_POOL_SIZE=1000
MWZZZH_SESSION_MAX_REQUESTS=50
MWZZZH_IMPERSONATE=chrome131_android

# 生成并发数（线程）
# 统一并发主开关：
# - generate_devices_bulk.py：控制设备生成并发
# - mwzzzh_spider.py：控制网络并发（MAX_CONCURRENCY）
# - goPlay/demos/stats/dgmain3：如果不设置 STATS_CONCURRENCY，会回退使用 GEN_CONCURRENCY
GEN_CONCURRENCY=200
# stats 项目并发（可选；优先级高于 GEN_CONCURRENCY）
STATS_CONCURRENCY=2000

# stats 设备连续失败阈值（用于“方式A：坏设备自动补位”）
# - 网络错误不会计入连续失败
# - 优先级：STATS_DEVICE_FAIL_THRESHOLD > DEVICE_FAIL_THRESHOLD > 默认 10
# STATS_DEVICE_FAIL_THRESHOLD=10

# stats cookies 连续失败阈值（达到后自动更换 cookies；网络错误不计入连续失败）
# - 仅 Redis 模式（COOKIES_SOURCE=redis）生效
# - 优先级：STATS_COOKIE_FAIL_THRESHOLD > COOKIE_FAIL_THRESHOLD > 默认 10
# STATS_COOKIE_FAIL_THRESHOLD=10

# stats 设备成功播放上限（达到后淘汰并补位；0=不启用）
# - 优先级：STATS_DEVICE_PLAY_MAX > DEVICE_PLAY_MAX > 默认 0
# STATS_DEVICE_PLAY_MAX=0
# stats 设备创建时间筛选：只使用 create_time 早于当前时间 N 小时的设备（适用于 file/redis）
# - 0=不筛选
# STATS_DEVICE_MIN_AGE_HOURS=0

# stats（Windows/非抢单模式）播放目标视频（视频ID，Linux 抢单模式会忽略它）
# AWEME_ID=7569635953183100191

# stats（抢单模式）开关：默认 Linux=1，Windows=0
# 本地/Windows 想模拟抢单测试：把 STATS_ORDER_MODE 改成 1，并配置好 DB_* 指向 orders 表
# STATS_ORDER_MODE=1
# 抢单模式 DB flush 间隔（秒）：每隔 N 秒把本轮新增 delivered 回写 MySQL，降低意外退出损失
STATS_ORDER_DB_FLUSH_SEC=5
# 抢单模式：允许重新抢 In progress 订单的“超时秒数”（进程崩溃/卡死恢复）
STATS_ORDER_STALE_SEC=120
# 抢单模式：轮询抢单间隔（毫秒）
STATS_ORDER_POLL_MS=1000

# 抢单模式：订单进度实时写 Redis 的 key 前缀
# - 实际 key：{prefix}:{order_id}（HASH：delivered/total/updated_at）
REDIS_ORDER_PROGRESS_PREFIX=tiktok:order_progress

# mwzzzh_spider 解析线程池大小（可选；不填则默认按 CPU 核心数自动推导：cores*2，范围 4~64）
# GEN_THREAD_POOL_SIZE=16

# 备份文件：每个文件最多条数（固定平均分到 10 个文件）
PER_FILE_MAX=100000

# mwzzzh_spider.py 写文件刷盘策略：
# - 默认只 flush（性能更好）
# - MWZZZH_FILE_FSYNC=1：每批写入后执行 fsync（更慢，但异常退出时更不容易丢）
# MWZZZH_FILE_FSYNC=0

# Redis 配置（二选一：REDIS_URL 或 host/port/db）
# REDIS_URL=redis://:password@127.0.0.1:6379/0
REDIS_HOST=127.0.0.1
REDIS_PORT=6379
REDIS_DB=0
REDIS_USERNAME=
REDIS_PASSWORD=a123456
REDIS_SSL=0

# Redis 超时配置（Go stats/signup 使用；避免高并发下 HMGET 出现 i/o timeout）
# REDIS_DIAL_TIMEOUT_SEC=10
# REDIS_READ_TIMEOUT_SEC=20
# REDIS_WRITE_TIMEOUT_SEC=20
# REDIS_POOL_TIMEOUT_SEC=30

# Redis 大 HMGET 分批参数（Go stats 读取设备时使用）
# - 值越小越稳但更慢；建议 100~500
# REDIS_HMGET_CHUNK=200

# Redis 批量加载超时（Go stats 从 Redis 扫描 ids + HMGET data 时使用）
# - 设备池/ cookie 池很大时建议调大，避免 context deadline exceeded
# REDIS_LOAD_TIMEOUT_SEC=120

# Redis 设备池 key 前缀 & 设备 id 字段
REDIS_DEVICE_POOL_KEY=tiktok:device_pool
REDIS_DEVICE_ID_FIELD=cdid

# stats/dgmain3：按命令行参数选择 cookies 池分库（device 池默认不分库）
# - go run . 1    => 使用 tiktok:startup_cookie_pool:1（device 仍为 tiktok:device_pool）
# - go run . 1 0  => deviceIdx=1（仅当 REDIS_DEVICE_POOL_SHARDS>1 时生效） + cookieIdx=0
# - 不传参       => 默认 0 号（不加后缀）
# 库数量（用于限制可用分库编号，超出则回退到 0）
REDIS_DEVICE_POOL_SHARDS=1
REDIS_COOKIE_POOL_SHARDS=3

# mwzzzh_spider.py（轮询补齐）设备池固定不分库：始终写入 REDIS_DEVICE_POOL_KEY（忽略 REDIS_DEVICE_POOL_SHARDS）

# signup（dgemail）设备创建时间筛选：只使用 create_time 早于当前时间 N 小时的设备（适用于 file/redis）
# - 0=不筛选
SIGNUP_DEVICE_MIN_AGE_HOURS=11

# Redis 最大保存设备数量（达到后按 use_count 最大淘汰）
REDIS_MAX_DEVICES=100000
# Redis 淘汰策略（默认 play：按播放次数最大淘汰；可选 use/attempt）
# REDIS_EVICT_POLICY=play

# startUp 注册 cookies 池（Go signup 写入、Go stats 读取）
REDIS_STARTUP_COOKIE_POOL_KEY=tiktok:startup_cookie_pool
# startUp 注册成功设备池（Go signup 写入、Go stats 可选读取）
# - 不配置时默认复用 REDIS_DEVICE_POOL_KEY
# REDIS_STARTUP_DEVICE_POOL_KEY=tiktok:startup_device_pool
# cookies 池最大数量（导入/写入时生效；超过后可在后台选择 evict 或返回剩余）
# REDIS_MAX_COOKIES=0

# dgemail（signup）轮询补齐 cookies：Linux 默认开启；Windows 可用 DGEMAIL_POLL_MODE=1 模拟调试
# - 轮询补齐：检查 Redis cookies 池数量，缺多少就自动注册补齐多少
# DGEMAIL_POLL_MODE=1
# DGEMAIL_POLL_INTERVAL_SEC=10
# 目标 cookies 池大小：统一使用 REDIS_MAX_COOKIES（每个池的最终数量）
# - REDIS_TARGET_COOKIES 已废弃（如配置会被忽略并提示）
# REDIS_TARGET_COOKIES=100000
# 单轮补齐最大注册数量（避免一次补太多）
# DGEMAIL_POLL_BATCH_MAX=2000
# dgemail 注册并发（默认 50）
# SIGNUP_CONCURRENCY=50
# startUp 注册次数（用于生成/收集 cookies 的目标数）
STARTUP_REGISTER_COUNT=100000
# signup 成功后是否把 cookies 写入 Redis（供 stats 使用）
SAVE_STARTUP_COOKIES_TO_REDIS=1
# signup 注册成功后是否把“设备（含 cookies 字段）”也写入 Redis 设备池（供 stats 从 Redis 取设备）
# - 默认行为：如果 SAVE_STARTUP_COOKIES_TO_REDIS=1，则这里不填也会默认写入
# SAVE_STARTUP_DEVICES_TO_REDIS=1
# stats 读取 cookies（推荐只用 COOKIES_SOURCE 控制，其他地方一致）
# - COOKIES_SOURCE=redis         ：从 Redis 的 startUp cookie 池读取（REDIS_STARTUP_COOKIE_POOL_KEY）
# - COOKIES_SOURCE=devices_file  ：从“设备文件每行的 cookies 字段”提取（适配 startUp 导出的设备文件）
#   典型用法（设备+cookies 都从 startUp 文件来）：
#     DEVICES_SOURCE=file
#     STATS_DEVICES_FILE=goPlay/demos/signup/dgemail/res/devices1221/devices12_21_3.txt
#     COOKIES_SOURCE=devices_file
# - 兼容旧写法：COOKIES_FROM_REDIS=1（不推荐，仅兼容）
COOKIES_SOURCE=redis
# COOKIES_LIMIT=100000

# 设备来源（Go signup / Go stats 读取设备的开关，推荐只用 DEVICES_SOURCE，其他地方一致）
# - 支持的取值：
#   - DEVICES_SOURCE=redis  ：从 Redis 设备池读取（Python 注册成功写入的设备池）
#   - DEVICES_SOURCE=file   ：从本地文件读取（文件路径可配置，见 DEVICES_FILE）
#   - DEVICES_SOURCE=（不填/其它任意值） ：等价于 file
# - 兼容旧写法：DEVICES_FROM_REDIS=1（不推荐，仅兼容；会覆盖 DEVICES_SOURCE）
# - DEVICES_LIMIT：从 Redis 读取时的最大设备数量（0 表示不限制；默认会回退 MAX_GENERATE）
# - DEVICES_FILE：设备 txt 文件路径（推荐统一配置；signup/stats 都会优先读取）
#   - 不配置时：stats 会向上查找仓库根目录的 devices.txt，否则用 dgmain3/devices.txt；signup 默认用 dgemail/data/devices.txt
DEVICES_SOURCE=redis
# DEVICES_LIMIT=100000

# 数据库配置（后续 Go 项目读取使用；本脚本暂不使用）
DB_HOST=38.148.242.37
DB_PORT=7708
DB_USER=tiktok_play_api
DB_PASSWORD=sSY4w6dkBb7r66bS
DB_NAME=tiktok_play_api

# Go API Server（api_server）
API_ADDR=0.0.0.0:8080
# API_KEY 从数据库 api_keys 表读取，不再使用 env 配置

# API Admin（新增/追加 api_key + 额度的页面）
# 填“管理员明文密码的 MD5(hex小写)”，后端会用 MD5(你输入的密码) 做校验
# 示例：echo -n tiktokAdmin | md5sum
ADMIN_PASSWORD_MD5=9a4cff57214ae9754476084a691eef5b

# API KEY Redis 永久缓存（api_server 使用）
REDIS_API_KEYS_KEY=tiktok:api_keys


